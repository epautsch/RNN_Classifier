{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-24T22:24:02.755259Z",
     "end_time": "2023-04-24T22:24:06.137864Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# Load the data\n",
    "data = pandas.read_csv('training.csv', usecols=['text', 'author'], sep=',', encoding='ISO-8859-1')\n",
    "texts = data['text']  # Extract the text column\n",
    "labels = data['author']-1  # Extract the label column\n",
    "\n",
    "# Convert the text into numerical sequences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "\n",
    "# Pad the sequences to a fixed length\n",
    "max_sequence_length = 1000  # Set the maximum sequence length\n",
    "sequences = sequence.pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "\n",
    "# Encode the labels into one-hot vectors\n",
    "num_classes = 50  # Set the number of classes\n",
    "labels = to_categorical(labels, num_classes)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 10001"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T22:24:12.924597Z",
     "end_time": "2023-04-24T22:25:24.136264Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create the model\n",
    "embedding_vector_length = 128\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vector_length, input_length=max_sequence_length))\n",
    "\n",
    "model.add(LSTM(400, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(400, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(400, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(50, activation='softmax')) # Output layer with 50 units and softmax activation\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T22:25:24.138265Z",
     "end_time": "2023-04-24T22:25:24.701266Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cosine_annealing(epoch, initial_learning_rate, T_max):\n",
    "    return initial_learning_rate * (1 + np.cos(np.pi * epoch / T_max)) / 2\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "T_max = 50  # Total number of epochs\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lambda epoch: cosine_annealing(epoch, initial_learning_rate, T_max))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T22:25:24.703268Z",
     "end_time": "2023-04-24T22:25:24.716266Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cosine_annealing(epoch, initial_learning_rate, T_max):\n",
    "    return initial_learning_rate * (1 + np.cos(np.pi * epoch / T_max)) / 2\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "T_max = 50  # Total number of epochs\n",
    "\n",
    "# Generate learning rates for each epoch\n",
    "epochs = np.arange(T_max)\n",
    "learning_rates = [cosine_annealing(epoch, initial_learning_rate, T_max) for epoch in epochs]\n",
    "\n",
    "# Plot the learning rates\n",
    "plt.plot(epochs, learning_rates)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Cosine Annealing Learning Rate Scheduler\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T23:06:58.501012Z",
     "end_time": "2023-04-24T23:06:58.642047Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # Use categorical_crossentropy loss for multiclass classification\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T22:25:25.346269Z",
     "end_time": "2023-04-24T22:25:25.473268Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filepath=\"best_model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=128, callbacks=[checkpoint, lr_scheduler])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
